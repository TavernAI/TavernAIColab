{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-Yihz3hAb2E"
      },
      "source": [
        "#<b></b>\n",
        "---\n",
        "\n",
        "https://colab.research.google.com/github/FunkEngine2023/TavernAIColab/blob/main/colab/GPU.ipynb<br>\n",
        "\n",
        "Works with:<br>\n",
        "KoboldAI https://github.com/KoboldAI/KoboldAI-Client<br>\n",
        "<br>\n",
        "**Links**<br>\n",
        "TavernAI Github https://github.com/TavernAI/TavernAI<br>\n",
        "TavernAI Discord https://discord.gg/zmK2gmr45t<br>\n",
        "TavernAI Boosty https://boosty.to/tavernai\n",
        "<pre>\n",
        " Tavern.AI/ \\ /  ^   ^ ^ ^    ~~~~ ^ \\     /  ^ ^   ^ ^/ ^  ^ \\/^  ^    \\\n",
        "         /^ ^\\ ^  ^ ^   ^ ^  ~~   ^   \\   /  ^  ^ ^   / ^ ^  ^/   ^ ^    \\\n",
        "        /^ ^ ^\\^   ^ ^ ^   _||____   ^ \\ /  ^  ^ ^   /       /  ^  ^  ^   \\\n",
        " /\\ /\\ /\\   ^  \\  /\\ /\\   /\\\\\\\\\\\\\\\\   ^ \\  ^ /\\ /\\ /\\   /\\ /\\ /\\  ^ ^  ^/\\\n",
        "//\\\\/\\\\/\\\\   ^  \\//\\\\/\\\\ /__\\\\\\\\\\\\\\\\  _, \\  //\\\\/\\\\/\\\\ //\\\\/\\\\/\\\\  ^ ^ //\\\\\n",
        "//\\\\/\\\\/\\\\       //\\\\/\\\\ |__|_|_|__|   \\__, //\\\\/\\\\/\\\\ //\\\\/\\\\/\\\\     ///\\\\\\\n",
        " || || (@＾◡＾)(≖ ‸ ≖*) ( ←_← )\\| /|   /\\ \\ヽ(°ㅂ°╬) |( Ψ▼ｰ▼)∈ (O_O; )  |||\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ~~~~~ ~~~~~ ~~~~~ ~~~~~  ~~~~~ ~~ \n",
        "</pre>\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "<h1>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; <b>Launch Instructions</b> </h1>\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "#This Colab notebook defaults to non-GPU runtime. Change to GPU standard if you intend to run KoboldAI models.\n",
        "\n",
        "##1: Horde users as well as NovelAI and OpenAI users load stupid fast now...\n",
        "## Pick the desired endpoint from the model list to use Horde, OpenAI, or NovelAI.\n",
        "<br>\n",
        "\n",
        "\n",
        "##2: The URL needed to access the TavernAI interface will appear essentially right away. You'll know it when it appears and can click into it right away and get it loading up in a new tab while you wait for your model to spin up.\n",
        "\n",
        " <br><b>**(If you're loading an actual model.)**</b></br>\n",
        "\n",
        "###3: You can putz around in tavern while Kobold-AI loads the model, e.g. browse Chara Cloud, select your character, adjust your settings, etc long before the Kobold-AI link drops into the console.<br>\n",
        "\n",
        "\n",
        "QUIT DOING DUMB THINGS. Please!\n",
        "\n",
        "> **--FunkEngine**\n",
        "\n",
        "**Faq**<br>\n",
        "* Q: My TavernAI link asks for an 'endpoint something or other' when I click the link, how do I get in?\n",
        "* A: To prevent redirection and reverse-proxies from being used for scamming or other nefarious purposes, currently you have to confirm the other end of the tunnel's public IP address before the link is established. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6kL-3-IoGCa"
      },
      "outputs": [],
      "source": [
        "#@title <h1><b>V-Tap this if you play on Mobile</b></h1> { run: \"auto\", vertical-output: true, form-width: \"100%\", display-mode: \"form\" }\n",
        "#Taken from KoboldAI colab\n",
        "%%html --isolated\n",
        "<audio loop autoplay src=\"https://henk.tech/colabkobold/silence.m4a\" controls></audio><b><br/>The silent audio track will hopefully convince your mobile browser that you're listening to music, and will keep this tab active.</b><br/><br/>I made the player itself start playing, no need to click it to start the playback.<br/>I also made it loop...<br/>If you're seriously here for 10+ hours...<br/>Stay hydrated, mmmmmkaaaayyy?<br/><br/><h1><b><video autoplay=\"\" src=\"https://github.com/FunkEngine2023/FunkEngine2023.github.io/raw/Funky_Notebooks/NFM.mp4\"></video>--FunkEngine</b></h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hps3qtPLFNBb"
      },
      "outputs": [],
      "source": [
        "#@title <h1><b>&emsp;&emsp;&emsp;&emsp;T<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;a<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;v<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;e<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;r<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;n<br>&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;A&ensp;I<br></b></h1> { form-width: \"53%\", display-mode: \"form\" }\n",
        "#@markdown # <- Click For Start (≖ ‸ ≖ ✿)&nbsp;NEW&nbsp;OPTION&nbsp;AVAILABLE. &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;**VVV**\n",
        "from IPython.display import HTML\n",
        "Model = \"Kobold Horde\" #@param [\"Kobold Horde\", \"NovelAI\", \"OpenAI\", \"Without Model\", \"Erebus 6B\", \"Nerybus 6B\", \"Nerys V2 6B\", \"\"] {allow-input: true}\n",
        "Version = \"Official\" \n",
        "KoboldAI_smuggling = \"CLOUDFLARE\" #@param [\"CLOUDFLARE\", \"LOCALTUNNEL\"]\n",
        "TavernAI_exfiltration = \"CLOUDFLARE\" #@param [\"CLOUDFLARE\", \"LOCALTUNNEL\"]\n",
        "#@markdown Store settings, softprompts, conversations, usercripts, preferences, and presets between sessions in Google Drive?\n",
        "use_google_drive = True #@param {type:\"boolean\"}\n",
        "#@markdown This is the **normal** 'use_google_drive?' you are familiar with.\n",
        "#@markdown ##**Tl;dr: Tick the box above like it normally is.**\n",
        "#@markdown # **If you have an expanded Google Drive already:**\n",
        "#@markdown ## You can vastly reduce the wait time for loading models.\n",
        "#@markdown **Enable this option** to save the model to your Google Drive.\n",
        "got_gigs = False #@param {type:\"boolean\"}\n",
        "#@markdown (Each individual model requires an average of 18GiB to store.)\n",
        "#@markdown #####If you tick the got_gigs option, loaded models will be saved to your Google Drive, and loaded from there going forward.\n",
        "#@markdown\n",
        "!rm -rf /content/sample_data/\n",
        "!rm -rf /content/.config/\n",
        "%cd /\n",
        "!npm install -g localtunnel\n",
        "import os\n",
        "import subprocess\n",
        "import time\n",
        "import sys\n",
        "import threading\n",
        "import requests\n",
        "from google.colab import drive\n",
        "\n",
        "if use_google_drive:\n",
        "  drive.mount('/content/drive/')\n",
        "  if not os.path.exists(\"/content/drive/MyDrive/TavernAI\"):\n",
        "    os.mkdir(\"/content/drive/MyDrive/TavernAI\")\n",
        "else:\n",
        "  if not os.path.exists(\"/content/drive\"):\n",
        "    os.mkdir(\"/content/drive\")\n",
        "  if not os.path.exists(\"/content/drive/MyDrive\"):\n",
        "    os.mkdir(\"/content/drive/MyDrive\")\n",
        "  if not os.path.exists(\"/content/drive/MyDrive/TavernAI\"):\n",
        "    os.mkdir(\"/content/drive/MyDrive/TavernAI\")\n",
        "\n",
        "\n",
        "if os.path.isfile(\"/TavernAIColab/taipid.txt\"):\n",
        "  taipid = open(\"/TavernAIColab/taipid.txt\").readline()\n",
        "  !kill -9 $taipid\n",
        "  print(\"Killing leftover TavernAI node.js process...\")\n",
        "  !rm -rf /TavernAIColab/taipid.txt\n",
        "taipid = ''\n",
        "if os.path.isfile(\"/content/ltpid.txt\"):\n",
        "  ltpid = open(\"/content/cfpid.txt\").readline()\n",
        "  !kill -9 $ltpid\n",
        "  print(\"Killing eftover zombie localtunnel process...\")\n",
        "  !rm -rf /content/cfpid.txt\n",
        "lturl = ''\n",
        "ltpid = ''\n",
        "if os.path.isfile(\"/content/cfpid.txt\"):\n",
        "  cfpid = open(\"/content/cfpid.txt\").readline()\n",
        "  !kill -9 $cfpid\n",
        "  print(\"Killing leftover zombie cloudflared tunnel process...\")\n",
        "  !rm -rf /content/ltpid.txt\n",
        "cfpid = ''\n",
        "needle = ''\n",
        "SmugglinKobolds = \"\"\n",
        "ENDPOINT = !curl ipecho.net/plain\n",
        "print(ENDPOINT)\n",
        "\n",
        "if TavernAI_exfiltration=='CLOUDFLARE':\n",
        "  %cd /content\n",
        "  if not os.path.isfile('/content/cloudflared-linux-amd64'):\n",
        "    !wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64\n",
        "    print(\"Getting Cloudflared!\")\n",
        "  else:\n",
        "    print(\"Has Cloudeflared from previous launch!\")\n",
        "  time.sleep(5)\n",
        "  os.chmod('/content/cloudflared-linux-amd64', 0o777)\n",
        "  !nohup /content/cloudflared-linux-amd64 tunnel --url http://127.0.0.1:8000 --metrics 127.0.0.1:31337 > cf.txt 2>&1 & echo -n $! > cfpid.txt\n",
        "  time.sleep(4)\n",
        "  print(\"Maybe it will give us a tunnel?\")\n",
        "  time.sleep(4)\n",
        "  scrape = requests.get('http://127.0.0.1:31337/metrics').text\n",
        "  haystack = scrape.partition('cloudflared_tunnel_user_hostnames_counts{userHostname=\"')[2]\n",
        "  needle = haystack.split('\"} 1')[0]\n",
        "  print(needle)\n",
        "  cfpid = open(\"cfpid.txt\").readline()\n",
        "  print(cfpid)\n",
        "  %cd /content/\n",
        "  if needle != '':\n",
        "    cloudflarelog = open('cloudflare.log', 'w')\n",
        "    cloudflarelog.write(\"CLOUDFLARE PROVIDES!\" + needle)\n",
        "    cloudflarelog.close()\n",
        "    print(\"HERE'S YOUR LINK!\" + needle)\n",
        "    print(\"Way harder than it needed to be...\")\n",
        "  scrape = needle\n",
        "  haystack = needle\n",
        "\n",
        "if TavernAI_exfiltration=='LOCALTUNNEL':\n",
        "  !nohup lt --port 8000 > lt.txt 2>&1 & echo -n $! > ltpid.txt\n",
        "  time.sleep(1)\n",
        "  lturl = open(\"lt.txt\").readline().strip().split(\"your url is: \")[1]\n",
        "  print(\"\")\n",
        "  !curl ipecho.net/plain\n",
        "  print(\"\")\n",
        "  print(lturl)\n",
        "  print(\"\")\n",
        "  !curl ipecho.net/plain\n",
        "  print(\"\")\n",
        "  ltpid = open(\"ltpid.txt\").readline()\n",
        "  print(ltpid)\n",
        "\n",
        "%cd /content/\n",
        "\n",
        "Provider=KoboldAI_smuggling\n",
        "Lightspeed = \"\"\n",
        "if got_gigs:\n",
        "  Lightspeed = \"--savemodel\"\n",
        "!nvidia-smi -pm 1\n",
        "!nvidia-smi -pl 69\n",
        "!nvidia-smi -c 3\n",
        "!nvidia-smi\n",
        "\n",
        "#Env\n",
        "Revision = \"\"\n",
        "colab_type = 2\n",
        "url = \"http://127.0.0.1:5000/api\"\n",
        "if Model == \"Kobold Horde\":\n",
        "  colab_type = 3\n",
        "  url = \"\"\n",
        "if Model == \"Without Model\":\n",
        "  colab_type = 5\n",
        "  url = \"\"\n",
        "if Model == \"OpenAI\":\n",
        "  colab_type = 5\n",
        "  url = \"\"\n",
        "if Model == \"NovelAI\":\n",
        "  colab_type = 5\n",
        "  url = \"\"\n",
        "\n",
        "\n",
        "%env colab=$colab_type\n",
        "%env colaburl=$url\n",
        "\n",
        "#TavernAI\n",
        "%cd /\n",
        "!node -v\n",
        "if os.path.exists(\"/TavernAIColab\"):\n",
        "  print(\"YOU RE-EXECUTED THE COLAB WITHOUT DELETING THE RUNTIME!\")\n",
        "  print(\"YOU RE-EXECUTED THE COLAB WITHOUT DELETING THE RUNTIME!\")\n",
        "  print(\"YOU RE-EXECUTED THE COLAB WITHOUT DELETING THE RUNTIME!\")\n",
        "  print(\"Funkengine will save you from yourself... This time...\")\n",
        "  time.sleep(10)\n",
        "\n",
        "if not os.path.exists(\"/TavernAIColab\"):\n",
        "  !git clone https://github.com/FunkEngine2023/TavernAIColab/\n",
        "time.sleep(1)\n",
        "%cd /TavernAIColab/\n",
        "!npm install\n",
        "time.sleep(1)\n",
        "\n",
        "#FunkEngine2023 now does what he originally intended to do here, not just what was merged prematurely...\n",
        "if use_google_drive:\n",
        "  %env googledrive=2\n",
        "  print(\"TavernAI 'total user expericnce persistence' features by FunkEngine!\")\n",
        "  %cd /\n",
        "  print(\"Starting with User Avatars...\")\n",
        "  if not os.path.exists(\"/content/drive/MyDrive/TavernAI/User Avatars\"):\n",
        "    print(\"Setting up Google Drive to hold avatars.\")\n",
        "    !mv -v '/TavernAIColab/public/User Avatars' '/content/drive/MyDrive/TavernAI/'\n",
        "    %cd /\n",
        "  if os.path.exists(\"/content/drive/MyDrive/TavernAI/User Avatars\") and not os.path.islink(\"/TavernAIColab/public/User Avatars\"):\n",
        "    print(\"Using existing avatars from your Google Drive new avatars stored as well.\")\n",
        "    !rm -rf '/TavernAIColab/public/User Avatars'\n",
        "    !ln -fs '/content/drive/MyDrive/TavernAI/User Avatars/' '/TavernAIColab/public/'\n",
        "    %cd /\n",
        "    print(\"Avatars shall persist between sessions.\")\n",
        "  if not os.path.isfile(\"/content/drive/MyDrive/TavernAI/settings.json\"):\n",
        "    print(\"First time here? Copying default settings for you so they persist when you change them...\")\n",
        "    !cp -f -p \"/TavernAIColab/public/settings.json\" \"/content/drive/MyDrive/TavernAI/settings.json\"\n",
        "    %cd /\n",
        "  if os.path.isfile(\"/content/drive/MyDrive/TavernAI/settings.json\") and not os.path.islink(\"/TavernAIColab/public/settings.json\"):\n",
        "    print(\"Linking settings from your Google Drive to be used instead of defaults.\")\n",
        "    !rm -f \"/TavernAIColab/public/settings.json\"\n",
        "    !ln -fs \"/content/drive/MyDrive/TavernAI/settings.json\" \"/TavernAIColab/public/settings.json\"\n",
        "    %cd /\n",
        "  if not os.path.isfile(\"/content/drive/MyDrive/TavernAI/config.conf\"):\n",
        "    print(\"First time here? Copying config.conf for you so you can edit it on Drive and change things like store characters as png instead of webp.\")\n",
        "    !cp -f -p \"/TavernAIColab/config.conf\" \"/content/drive/MyDrive/TavernAI/config.conf\"\n",
        "    %cd /\n",
        "  if os.path.isfile(\"/content/drive/MyDrive/TavernAI/config.conf\")and not os.path.islink(\"/TavernAIColab/config.conf\"):\n",
        "    print(\"Linking config.conf from your Google Drive to override defaults.\")\n",
        "    !rm -f \"/TavernAIColab/config.conf\"\n",
        "    !ln -fs \"/content/drive/MyDrive/TavernAI/config.conf\" \"/TavernAIColab/config.conf\"\n",
        "    %cd /\n",
        "  if not os.path.exists(\"/content/drive/MyDrive/TavernAI/characters\"):\n",
        "    print(\"Setting up Google Drive to hold characters.\")\n",
        "    !mv -v /TavernAIColab/public/characters /content/drive/MyDrive/TavernAI/\n",
        "    %cd /\n",
        "  if os.path.exists(\"/content/drive/MyDrive/TavernAI/characters\") and not os.path.islink(\"/TavernAIColab/public/characters\"):\n",
        "    print(\"Using existing characters from your Google Drive new characters will be stored there as well.\")\n",
        "    !rm -rf /TavernAIColab/public/characters\n",
        "    !ln -fs /content/drive/MyDrive/TavernAI/characters/ /TavernAIColab/public/\n",
        "    %cd /\n",
        "  if not os.path.exists(\"/content/drive/MyDrive/TavernAI/chats\"):\n",
        "    print(\"Don't you rememeber what they took from us? Setting up Google Drive to remember the past.\")\n",
        "    !mv -v /TavernAIColab/public/chats /content/drive/MyDrive/TavernAI/\n",
        "    %cd /\n",
        "  if os.path.exists(\"/content/drive/MyDrive/TavernAI/chats\") and not os.path.islink(\"/TavernAIColab/public/chats\"):\n",
        "    print(\"Using your conversation history from Google Drive. Always remember what they took from us!\")\n",
        "    !rm -rf /TavernAIColab/public/chats\n",
        "    !ln -fs /content/drive/MyDrive/TavernAI/chats/ /TavernAIColab/public/\n",
        "    %cd /\n",
        "  if not os.path.exists(\"/content/drive/MyDrive/TavernAI/backgrounds\"):\n",
        "    print(\"I've heard talk that backgrounds are an extremely super important to some of you...\")\n",
        "    !mv -v /TavernAIColab/public/backgrounds /content/drive/MyDrive/TavernAI/\n",
        "    %cd /\n",
        "  if os.path.exists(\"/content/drive/MyDrive/TavernAI/backgrounds\") and not os.path.islink(\"/TavernAIColab/public/backgrounds\"):\n",
        "    print(\"------\")\n",
        "    print(\"I suppose we can bring the scenery along as well...\")\n",
        "    print(\"------\")\n",
        "    print(\"------\")\n",
        "    print(\"'Some of you seem oddly passionate about your custom backgrounds...' --FunkEngine Spring of 2023.\")\n",
        "    print(\"------\")\n",
        "    print(\"------\")\n",
        "    !rm -rf /TavernAIColab/public/backgrounds\n",
        "    !ln -fs /content/drive/MyDrive/TavernAI/backgrounds/ /TavernAIColab/public/\n",
        "    print(\"Background storage linked!\")\n",
        "  print(\"That should be everything set up the way it was before...\")\n",
        "  print(\"TavernAI user experience continuity is implied but not guaranteed.\")\n",
        "elif not use_google_drive:\n",
        "  print(\"Didn't pick drive, you get nothing!\")\n",
        "\n",
        "print(\"DONE\")\n",
        "%cd /content/\n",
        "\n",
        "# Are we loading models? If we are...\n",
        "# KoboldAI takes the wheel and drives then. (Retains control of console.)\n",
        "# TavernAI gets nohupped into the back of the van. (Black-bagged candy carpet shovels and all!)\n",
        "if colab_type == 2:\n",
        "  if Model == \"Nerys V2 6B\":\n",
        "    Model = \"KoboldAI/OPT-6B-nerys-v2\"\n",
        "    path = \"\"\n",
        "    download = \"\"\n",
        "  elif Model == \"Nerybus 6B\":\n",
        "    Model = \"KoboldAI/OPT-6.7B-Nerybus-Mix\"\n",
        "    path = \"\"\n",
        "    download = \"\"\n",
        "  elif Model == \"Erebus 6B\":\n",
        "    Model = \"KoboldAI/OPT-6.7B-Erebus\"\n",
        "    path = \"\"\n",
        "    download = \"\"\n",
        "  %cd /TavernAIColab/\n",
        "  !nohup node server.js > tai.txt 2>&1 & echo -n $! > taipid.txt\n",
        "  time.sleep(6)\n",
        "  taiurl = open(\"tai.txt\")\n",
        "  print(taiurl.readline())\n",
        "  print(taiurl.readline())\n",
        "  print(taiurl.readline())\n",
        "  print(taiurl.readline())\n",
        "  taiurl.close()\n",
        "  print(\"That is not your link.\")\n",
        "  print(\"But it means your Tavern is spinning up.\")\n",
        "  print(\"Soon.(tm)\")\n",
        "  taipid = open(\"taipid.txt\").readline()\n",
        "  print(taipid)\n",
        "  %cd /content/\n",
        "  !wget -q https://koboldai.org/ckds -O - | bash /dev/stdin --init only --model $Model -g united $SmugglinKobolds $Lightspeed --colab\n",
        "  print(\"KoboldAI prepped and ready to load the model!\")\n",
        "  print(\"TavernAI is running.\")\n",
        "  print(\"Launching KoboldAI Now to load your selected model.\")\n",
        "  print(\"Click your TavernAI link and enter the IP if/when asked.\")\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "  !curl ipecho.net/plain\n",
        "  print(\"\")\n",
        "  print(lturl)\n",
        "  print(needle)\n",
        "  print(\"\")\n",
        "  !curl ipecho.net/plain\n",
        "  print(\"\")\n",
        "  print(\"\")\n",
        "  print(\"I cannot stress how fully loaded and ready TavernAI is. You should go there now.\")\n",
        "  print(\"Handing the console off to KoboldAI now, don't worry about 'attention' and 'padding' token errors.\")\n",
        "  print(\"They're prefectly normal, there's nothing you can do about them, and they have always been there you've just never been able to see them.\")\n",
        "  %cd /content/KoboldAI-Client/\n",
        "  Lightspeed = \"\"\n",
        "  if got_gigs:\n",
        "    Lightspeed = \"--savemodel\"    \n",
        "  SmugglinKobolds = \"\"\n",
        "  if KoboldAI_smuggling == \"LOCALTUNNEL\":\n",
        "    SmugglinKobolds = \"--localtunnel\"\n",
        "  !python3 aiserver.py --colab --lowmem --quiet --nobreakmodel --remote --model $Model $Lightspeed $SmugglinKobolds\n",
        "\n",
        "#No need for KoboldAI...\n",
        "#We give TavernAI the helm...\n",
        "if colab_type != 2:\n",
        "  print(\"You selected Horde, Without Model, NovelAI or OpenAI from the menu.\")\n",
        "  print(\"Tavern is installed and set to use your settings, characters, chats, avatars, etc from Google Drive.\")\n",
        "  print(\"Here's your TavernAI link and the endpoint IP to give if/when asked to do so.\")\n",
        "  print(\"\")\n",
        "  !curl ipecho.net/plain\n",
        "  print(\"\")\n",
        "  print(\"HERE'S YOUR **CLOUDFLARE** LINK!\" + needle)\n",
        "  print(\"Way harder than it needed to be...\")\n",
        "  print(\"HERE'S YOUR **LOCALTUNNEL** LINK!\" + lturl)\n",
        "  print(\"\")\n",
        "  !curl ipecho.net/plain\n",
        "  print(\"\")\n",
        "  print(\"Handing the console off to TavernAI now.\")\n",
        "  print(\"Do not be frightened. If you don't know what you're looking at, that's fine.\")\n",
        "  print(\"Just watch the pretty colors scroll by as you interact with your characters.\")\n",
        "  print(\"But at least now you can see if an error occurs and things stop working suddenly.\")\n",
        "  print(\"--Funkengine\")\n",
        "  %cd /TavernAIColab/\n",
        "  !node server.js"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
